<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">
    <link rel="stylesheet" href="https://dobrian.github.io/cmp/static/css/cmp.css" />
    <title>Computer Music Programming</title>
  </head>
  <body>
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
      <ul class="navbar-nav mr-auto">
        <li class="nav-item">
          <a class="nav-link" href="https://dobrian.github.io/cmp">Computer Music Programming</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://dobrian.github.io/cmp/examples.html">Examples</a>
        </li>
      </ul>
    </nav>
    <div class="container">
      <h1 id="computer-music-programming">List of Examples</h1>
      <hr />
      <h2><a name="max">Max Examples</a></h2>
      <p>
      The largest single collection of Max examples is the <a href="http://music.arts.uci.edu/dobrian/maxcookbook/">Max Cookbook</a>. You can find specific examples there by title or by keyword search.
      </p>
      <p><strong>[Each image below is linked to a file of JSON code containing the actual Max patch.<br />
        Right-click on an image to download the .maxpat file directly to disk, which you can then open in Max.]</strong>
      </p>

      <p>
        <a name="Ex00"><b>Example 0</b></a>: Line and Line~
      </p>
      <div class="row">
        <div class="col">
          <video controls
                 src="topics/control-signals/2.line_object_tutorial.mp4"
                 width="100%"
                 height="100%"
                 >
        </div>
        <div class="col">
          <video controls
                 src="topics/control-signals/2.line~_object_tutorial.mp4"
                 width="100%"
                 height="100%"
                 >
        </div>
      </div>
      <br>
      <p><b>Line object</b></p>
      <p>Often we will find ourselves in the situation where we need to automate the change of a certain value in time, even if only to free ourselves from the burden of having to control the machine. Though there are always multiple ways to achieve the same result, as it happens in most programming languages, in Max we have an object whose sole purpose is to help us solve this specific problem. The line object can interpolate between two numbers in a given time interval. Given a new line object, we can put it to work by sending it a list with 2 numbers. The first number is the number that we want to reach; the second number is the time interval, in milliseconds, for that number to be reached. Using your max skills you can change this message box to include a place holder, so that you don't have retype the message box everytime you need to change its values. Should you send it a single value, the line object will immediatelly jump to that number. Furthermore, you can use this technique to your advantage if you decide to always have the numbers changing in the same fashion, say from 10 to 50 in 1500 milliseconds with the push of a button. Finally, you can also instruct the line object to work with floats, instead of integers, if you set the first argument as an initial floating point number.
      </p>
      <p><b>Line~ object</b></p>
      <p>As with many other objects in Max, the line object also has its MSP counterpart, the line~ object. This object functions very much like its Max counterpart with the exception that it outputs a signal instead of a stream of messages. Again, by sending it a list with two numbers the line~ object will interpolate between its current value and the first number you are sending, in the time interval of the second number on the list. This second number can also be sent to the second inlet. The line~ object only has two inlets instead of three because the time grain, the rate at which it is updating its internal value (the values that get sent out) is determined by the audio status settings. Having line object that works in the signal domain allow us to directly interact with other MSP objects. Here I'm multiplying the output of the line~ with the output of a cycle~ object. And sure enough, we can send a longer list of values in order to sculpt our signal with the precision we need. In this example, I will have the sound fade in during 2 seconds, fade out during 2 seconds, jump to full volume and stay there for 200 milliseconds, jump to silence and stay there for 200 milliseconds, and finally jump back to full volume and fade out during 2 seconds.
      </p>
      
      <p>
        <a name="Ex01"><b>Example 1</b></a>: Fade-in and fade-out
      </p>
      <p>
        <a href="examples/max/patches/fadeinfadeoutdemo.maxpat"><img src="examples/max/images/fadeinfadeoutdemo.png" width=467 height=484 alt="Example 1" border=0></a>
      </p>
      <p>
      This shows the use of linear interpolation from one amplitude to another to create a smooth fade-in or fade-out. The <b>line~</b> object expects to receive a ramp time in milliseconds in its right inlet, and then a destination value in its left inlet. (It can also receive those two numbers as a two-item list, &lt;destination value&gt;&lt;ramp time&gt;, in its left inlet.) Its output signal will then change linearly from its current value to its new destination value in the specified amount of time. Once it arrives at the destination value, its output signal stays constant at the new value.
      </p>
      <p>
      Because the fade-out takes a non-zero amount of time, it's necessary to delay stopping the sound file until the fade-out has taken place. So, whereas we can start the fade-in at the same time as we start the sound file, we need to wait for the fade-out to finish before we stop the file. So, we look for the off message (0), using a <b>select</b> object, which will send out a <i>bang</i> when it receives a match, and we then delay that bang with a <b>delay</b> object until the fade-out is done, then the <i>bang</i> triggers the message <i>0</i> to stop the <b>sfplay~</b> object.
      </p>
      <p>
        <a name="Ex02"><b>Example 2</b></a>: Vibrato by means of frequency modulation
      </p>
      <p>
        <a href="examples/max/patches/modulationdemo.maxpat"><img src="examples/max/images/modulationdemo.png" width=899 height=483 alt="Example 2" border=0></a>
      </p>
      <p>
      The <b>cycle~</b> object is an oscillator that produces a sinusoidal tone at any specified frequency. At an audio frequency we can listen to it, and at a sub-audio frequency we can use it as a low-frequency oscillator (LFO) to modulate some parameter of a sound. This patch demonstrates frequency modulation to create a vibrato effect. Try changing the different number boxes until you have a good experience of how each parameter affects the sound, especially the rate and depth of the frequency modulation caused by the modulating oscillator. Try some extreme values to get extreme effects.
      </p>
      <p>
      Because the fade-out takes a non-zero amount of time, it's necessary to delay stopping the sound file until the fade-out has taken place. So, whereas we can start the fade-in at the same time as we start the sound file, we need to wait for the fade-out to finish before we stop the file. So, we look for the off message (<i>0</i>), using a <b>select</b> object, which will send out a <i>bang</i> when it receives a match, and we then delay that bang with a <b>delay</b> object until the fade-out is done, then the <i>bang</i> triggers the message <i>0</i> to stop the <b>sfplay~</b> object.
      </p>
      <p>
        <a name="Ex03"><b>Example 3</b></a>: MIDI Keyboard Example
      </p>
      <p>
        <a href="examples/max/patches/midikeyboard.maxpat"><img src="examples/max/images/midikeyboard.png" class="img-fluid"></a>
      </p>
      <p>
        <a name="Ex04"><b>Example 4</b></a>: Mouse Theremin
      </p>
      <p>
        <a href="examples/max/patches/mousetheremin.maxpat"><img src="examples/max/images/mousetheremin.png" class="img-fluid"></a>
      </p>
      <p>
        <a name="Ex05"><b>Example 5</b></a>: Saw Synth Demo
      </p>
      <p>
        <a href="examples/max/patches/sawsynthdemo.maxpat"><img src="examples/max/images/sawsynthdemo.png" class="img-fluid"></a>
      </p>
      <p>
        <a name="Ex06"><b>Example 6</b></a>: Schedule a future event
      </p>
      <p>
        <a href="examples/max/patches/schedulefutureevent.maxpat"><img src="examples/max/images/schedulefutureevent.png" width=544 height=306 alt="Example 6" border=0></a>
      </p>
      <p>
        Timing is very important in music. The fundamental way to ensure precise timing of events is to use a scheduler. A schedule is a list of time-tagged events to be executed at specific times in the future. That schedule must be consulted constantly at regular intervals (as often as possible, e.g., every millisecond) to see if any item on the list has a time tag that is less than or equal to the current time; if so, that event should be enacted.
      </p>
      <p>
        Max has a master scheduler constantly running behind the scenes, and has various objects that allow you to post events on the schedule. The simplest of all of those is the <b>delay</b> object. When <b>delay</b> receives a <i>bang</i> in its left inlet, it schedules that <i>bang</i> to be sent out its outlet after a delay of a certain number of milliseconds, which has been specified in its right inlet. (Alternatively, if <b>delay</b> receives an <i>int</i> or a <i>float</i> in its left inlet, it uses that number to set its delay time, overwriting whatever number was previously set as the delay time, and schedules a <i>bang</i> to be sent out after that number of milliseconds has elapsed.)
      </p>
      <p>
        The <b>delay</b> object can schedule only one <i>bang</i> at a time. If another <i>bang</i>, <i>int</i>, or <i>float</i> is received in its left inlet before the previously-scheduled <i>bang</i> has been sent out, the previously-scheduled <i>bang</i> will be pre-empted and the new <i>bang</i> will be scheduled instead. The message <i>stop</i> in the left inlet cancels any currently-scheduled <i>bang</i>. If the delay time in the right inlet is changed while a <i>bang</i> is scheduled, that doesn't change the timing of the existing scheduled <i>bang</i>; the new delay time only affects subsequently-scheduled <i>bang</i>s.
      </p>
      <p>
        In this example, we use a bass drum sound and a snare drum sound as two stand-ins for the idea of "an event", but in fact an event can be any Max message, or combination of messages, even turning on or off other entire processes. The delay time might be only a few milliseconds, to make two things happen in rapid precisely-timed succession, or it could be a much longer time (though still expressed in terms of milliseconds) such as several seconds, minutes, or even hours.
      </p>
      <p>
        Although it's not demonstrated in this example, it's also possible to specify the delay time in <a href="https://docs.cycling74.com/max7/vignettes/maxtime_syntax">tempo-relative time units</a>, such as <i>4n</i> for a quarter note, based on the current tempo of the Max <a href="https://docs.cycling74.com/max7/maxobject/transport">transport</a>, but in that case <b>delay</b> will only work when the transport is on.
      </p>
      <p>
        The Max <b>delay</b> object is comparable to the <code>setTimeout()</code> method in JavaScript. When using JavaScript within a Max <b>js</b> object, the <code>setTimeout()</code> method is not available; the nearest equivalent is the <code>schedule()</code> method of <a href="https://docs.cycling74.com/max7/vignettes/jstaskobject">the Task() object</a>, but that will run in a low-priority thread of Max, not in the high-priority scheduler as Max's <b>delay</b> object does.
      </p>
      <p>
        <a name="Ex07"><b>Example 7</b></a>: DIY ring buffer
      </p>
      <p>
        <a href="examples/max/patches/ringbufferdemo.maxpat"><img src="examples/max/images/ringbufferdemo.png" width=741 height=545 alt="Example 7" border=0></a>
      </p>
      <p>
        For time-delayed audio, we need to create what's called a "<a href="https://en.wikipedia.org/wiki/Circular_buffer">circular buffer</a>" or a "ring buffer", an array of samples to which we record continuously in a loop, and which we can then use always to access the most recently recorded sound from the past.
      </p>
      <p>
        The MSP object <b>delay~</b> does exactly that. And another pair of objects&mdash;<b>tapin~</b> and <b>tapout~</b> does the same thing, but with a minimum delay of one signal vector so that you can even feed the delayed sound back into the delay loop. However, in this example, we build and access a ring buffer ourselves, just to demonstrate inner workings of the process in a little more detail.
      </p>
      <p>
        The <b>buffer~</b> object creates an array in RAM for storing sound and accessing it in a variety of ways. Here we create a one-second buffer, and we use a sample counter (the <b>count~</b> object) to put each sample of the incoming sound (from <b>adc~</b>) into that array, using the <b>poke~</b> object to access individual sample locations in the array. At the same time, we can use that same sample counter, which is always pointing to the location of the current time in the array, to calculate the signal some amount of time (some number of samples) in the past. If the current time in samples minus the delay time in samples is less than 0, we need to wrap the calculated sample location back into the array (by adding the number of samples in the array); that's what the <b>pong~</b> object does for us.
      </p>
      <p>
        You can try this out yourself, but beware of the possibility of feedback, since this patch sends the incoming sound from <b>adc~</b>, with some delay, right back out via the <b>dac~</b>.
      </p>
      <p>
        <a name="Ex08"><b>Example 8</b></a>: Algorithmic demo with phasor
      </p>
      <p>
        <a href="examples/max/patches/algorithmicdemowithphasor.maxpat"><img src="examples/max/images/algorithmicdemowithphasor.png" width=544 height=306 alt="Example 8" border=0></a>
      </p>
      <p>
        <a name="Ex09"><b>Example 9</b></a>: Amplitude is inversely proportional to distance
      </p>
      <p>
        <a href="examples/max/patches/distance&amplitude.maxpat"><img src="examples/max/images/distance&amplitude.png" width=412 height=346 alt="Example 9" border=0></a>
      </p>
      <p>
        Our tympanic membrane (a.k.a. our eardrum) and a microphone are both devices that measure sound intensity. When a sound arrives at our eardrum or at the diaphragm of a microphone, either of which has a certain surface area, the power in that area (i.e. the intensity) is detected. However, the intensity of a sound, as measured by an eardrum or a microphone, will differ depending on the distance from the sound's source, because the sound is being emitted from the source in <u>all</u> directions. If you think of the sound energy as radiating outward from the source in a spherical pattern, and you bear in mind that the surface of a sphere is proportional to the square of its radius (the surface area of a sphere is equal to <em>4πr<sup>2</sup></em>), you can understand that the intensity of a sound as measured in a given surface area is inversely proportional to the square of the distance of the point of measurement from the sound source. This principle is known as the <a href="http://hyperphysics.phy-astr.gsu.edu/hbase/Forces/isq.html"><em>inverse square law</em></a>: intensity is inversely proportional to the square of the distance from the source (<em>I &prop; 1/d<sup>2</sup></em>).
      </p>

      <p>
        Our subjective sense of a sound's "loudness" is not the same as its intensity, but is generally roughly proportional to it. But what does that mean in terms of the <u>amplitude</u> factor we'll use to alter a sound's intensity in digital audio? As defined in physics, the intensity of a wave is proportional to the square of its amplitude (<em>A<sup>2</sup> &prop; I</em>). So that means that if we want to emulate the effect of a sound being twice as far away, (1/4 the intensity), we would need to multiply the amplitude by one-half. Indeed, based on what we know about the relationship between distance and intensity (the inverse square law, <em>I &prop; 1/d<sup>2</sup></em>), we can see that the relationship between distance and amplitude is simply <em>A ∝ 1/d</em>; amplitude is inversely proportional to distance.
      </p>

      <p>
        This patch shows how you can emulate a change of distance simply by changing its relative amplitude inversely. Of course, our sense of distance is also affected by reverberation and high-frequency rolloff, but this basic relationship between distance and ampitude is useful to know for sound spatialization.
      </p>

      <hr />

      <h2><a name="webaudio">WebAudio Examples</a></h2>

      <p>
        <a name="Ex01js"><b>Example 1</b></a>: Synthesizer with vibrato
      </p>

      <p>Here is a basic synthesizer in Web Audio, designed by Chris, with a sawtooth oscillator, a simple attack-release amplitude envelope, and sinusoidal vibrato by means of frequency modulation with an LFO. The notes are played by keys of the computer keyboard. MIDI velocity is simulated by setting a note-on velocity value to control the notes' peak amplitude. The rate and depth of the vibrato can also be set by the user.
      </p>

      <p>
        <a href="examples/javascript/vibratosynth.html">Synthesizer with vibrato</a>
      </p>

      <p>
        There are lots of explanatory comments in the <a href="examples/javascript/vibratosynth.js">vibratosynth.js</a> file.
      </p>
    </div>
  </body>
</html>
